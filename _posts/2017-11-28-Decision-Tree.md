---
layout: post
title: 决策树
---

## 决策树算法（分类、回归）

### 1.1基础算法
#### 1.1.2 决策树是一个if-then规则集合
* 输入:
  - 训练集:$D=\{(x_1,y_1),(x_2,y_2)...,(x_m,y_m)\}$
  - 属性集:$A=\{a_1,a_2,...,a_d\}$
* 输出：以node为结点的决策树
>1. 生成结点node；
>2. **if** D中样本属于同一类别C **then**
>3. 将node标记为C类的叶结点；**return**
>4. **endif**
>5. **if** $A=\emptyset$ **OR** D中的样本点在A中取值相同 **then**
>6.  将node标记为叶结点，类型为D中样本最多的类型；**return**
>7. **endif**
>8. 将A中选择最优划分属性$a_*$
>9. **for** $a_#$中每一个值$a^v_#$ **do**
>10.  为node生成一个分支，令$D_v$表示在$a_*$上取值为$a^v_*$的样本子集；
>11. **if** $D_v$为空 **then**
>12. 将分支结点标记为叶结点，其类别标记为D中样本最多的类； **return**
>13. **else**
>14. 以TreeGenerate

2. 决策树具有互斥完备性，即样本中每个实例都被有且仅有一条路径覆盖。



